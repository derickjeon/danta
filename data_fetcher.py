import requests
from bs4 import BeautifulSoup
from pycoingecko import CoinGeckoAPI
import feedparser

# ğŸ“Š êµ­ë‚´ ì¦ì‹œ ìš”ì•½
def get_korea_market_summary():
    url_sise = 'https://finance.naver.com/sise/'
    url_fx = 'https://finance.naver.com/marketindex/'

    try:
        response = requests.get(url_sise)
        soup = BeautifulSoup(response.text, 'html.parser')
        kospi = soup.select_one('#KOSPI_now').text.strip()
        kosdaq = soup.select_one('#KOSDAQ_now').text.strip()
    except:
        kospi = 'ì •ë³´ ì—†ìŒ'
        kosdaq = 'ì •ë³´ ì—†ìŒ'

    try:
        ex_response = requests.get(url_fx)
        ex_soup = BeautifulSoup(ex_response.text, 'html.parser')
        usd = ex_soup.select_one('span.value').text.strip()
    except:
        usd = 'ì •ë³´ ì—†ìŒ'

    try:
        cad_url = 'https://www.x-rates.com/calculator/?from=CAD&to=KRW&amount=1'
        cad_response = requests.get(cad_url, headers={'User-Agent': 'Mozilla/5.0'})
        cad_soup = BeautifulSoup(cad_response.text, 'html.parser')
        cad_text = cad_soup.select_one('span.ccOutputTrail').previous_sibling
        cad = cad_text.strip()
    except:
        cad = 'ì •ë³´ ì—†ìŒ'

    return {
        'KOSPI': kospi,
        'KOSDAQ': kosdaq,
        'í™˜ìœ¨ (USD/KRW)': usd,
        'í™˜ìœ¨ (CAD/KRW)': cad
    }

# ğŸª™ ì½”ì¸ ìš”ì•½
def get_crypto_market_summary():
    cg = CoinGeckoAPI()
    data = cg.get_price(ids=['bitcoin', 'ethereum'], vs_currencies='usd', include_24hr_change='true')

    btc = data['bitcoin']
    eth = data['ethereum']

    return {
        'Bitcoin': f"${btc['usd']} ({btc['usd_24h_change']:.2f}% ë³€í™”)",
        'Ethereum': f"${eth['usd']} ({eth['usd_24h_change']:.2f}% ë³€í™”)"
    }

# ğŸŒ ì¤‘ìš” ê²½ì œ ë‰´ìŠ¤ ì„ ë³„
import feedparser

def get_main_news():
    korean_feeds = [
        ('ë§¤ì¼ê²½ì œ', 'https://www.mk.co.kr/rss/30000001/'),
        ('í•œêµ­ê²½ì œ', 'https://rss.hankyung.com/economy.xml'),
        ('ì—°í•©ë‰´ìŠ¤', 'https://www.yna.co.kr/economy/rss'),
    ]
    english_feeds = [
        ('Bloomberg', 'https://feeds.bloomberg.com/markets/news.rss'),
        ('Reuters', 'https://feeds.reuters.com/reuters/businessNews'),
        ('CNBC', 'https://www.cnbc.com/id/100003114/device/rss/rss.html'),
    ]

    exclude_keywords = ['êµìœ¡', 'ì„¸ë¯¸ë‚˜', 'í–‰ì‚¬', 'ì „ì‹œ', 'í›„ì›', 'ì¶•ì œ', 'í™ë³´', 'ìº í˜ì¸', 'ê°•ì¢Œ', 'ì „ë‹¬ì‹']

    def fetch_from_source(name, url, per_feed=3):
        news_items = []
        feed = feedparser.parse(url)
        for entry in feed.entries:
            title = entry.title if hasattr(entry, 'title') else entry.get('summary', 'No Title')
            link = entry.link
            if not any(word in title for word in exclude_keywords):
                news_items.append((f"[{name}] {title}", link))
            if len(news_items) >= per_feed:
                break
        # ë§Œì•½ ë‰´ìŠ¤ê°€ ë¶€ì¡±í•˜ë©´ "í˜„ì¬ ë‰´ìŠ¤ ì—†ìŒ"ìœ¼ë¡œ ì±„ì›€
        while len(news_items) < per_feed:
            news_items.append((f"[{name}] í˜„ì¬ ë‰´ìŠ¤ ì—†ìŒ", "#"))
        return news_items

    korean_news = []
    for name, url in korean_feeds:
        korean_news.extend(fetch_from_source(name, url, per_feed=3))

    english_news = []
    for name, url in english_feeds:
        english_news.extend(fetch_from_source(name, url, per_feed=3))

    return korean_news + english_news  # í•œêµ­+ì˜ì–´ ë‰´ìŠ¤ í•©ì¹˜ê¸°



# ë‹¨ë… ì‹¤í–‰ í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    print("ğŸ“Š êµ­ë‚´ ì¦ì‹œ ìš”ì•½:")
    print(get_korea_market_summary())

    print("\nğŸª™ ì½”ì¸ ìš”ì•½:")
    print(get_crypto_market_summary())

    print("\nğŸŒ ì£¼ìš” ë‰´ìŠ¤:")
    for title, link in get_main_news():
        print("-", title, "->", link)
